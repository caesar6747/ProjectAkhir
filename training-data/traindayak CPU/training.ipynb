{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "b6ZIUpwFih7a",
    "outputId": "3f00b5c8-d94c-4f2b-c0a4-0d80a4b9224a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\ndrive.mount('/gdrive')\\n%cd /gdrive\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQ7C1ecfiqcI"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from numpy import array, argmax, random, take\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNGRU\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import unicodedata\n",
    "import io\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o88uz_9kmSxS"
   },
   "outputs": [],
   "source": [
    "#path_to_file = '/content/fra1.txt'\n",
    "#path_to_file = '/content/drive/My Drive/Colab Notebooks/fra1.txt'\n",
    "path_to_file = 'dayak.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OB9IkJCm75L"
   },
   "outputs": [],
   "source": [
    "def unicode_to_acii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itS-QoVznJ64"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_acii(w.lower().strip())\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "  w = w.strip()\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RXJryIzrr_-s",
    "outputId": "ce3f3d99-96a0-4c55-a365-eaf9b1a47a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> puis je emprunter ce livre ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "fr_sentence = u\"Puis-je emprunter ce livre?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(fr_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWrJ3arQtBpY"
   },
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "uSPFRdBIt9eM",
    "outputId": "6b9c77bc-1a71-4aaa-b51c-2782379e7488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> apa kabar <end>\n",
      "<start> narai kabar <end>\n",
      "====\n",
      "<start> apa katanya <end>\n",
      "<start> narai kua <end>\n",
      "====\n",
      "<start> aku pulang <end>\n",
      "<start> aku buli <end>\n",
      "====\n",
      "<start> aku sedang belajar <end>\n",
      "<start> aku lagih belajar <end>\n",
      "====\n",
      "<start> aku mau makan <end>\n",
      "<start> aku handak kuman <end>\n",
      "====\n",
      "<start> aku datang <end>\n",
      "<start> aku dumah <end>\n",
      "====\n",
      "<start> aku pergi <end>\n",
      "<start> aku tulak <end>\n",
      "====\n",
      "<start> aku sudah menjawab pertanyaan <end>\n",
      "<start> aku jadi manjawab pertanyaan <end>\n",
      "====\n",
      "<start> aku suka kamu <end>\n",
      "<start> aku handak dengam <end>\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "en, fr = create_dataset(path_to_file, None)\n",
    "for s in range(9):\n",
    "    print(en[s])\n",
    "    print(fr[s])\n",
    "    print('====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGZ6n267uGC4"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQ8FB5U9y1jU"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "  \n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sWcBu21y3mn"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 2222\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x0000020AB1A032E0>\n"
     ]
    }
   ],
   "source": [
    "print(inp_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('inp_lang.pickle', 'wb') as handle:\n",
    "    pickle.dump(inp_lang, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('targ_lang.pickle', 'wb') as handle:\n",
    "    pickle.dump(targ_lang, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "#with open('tokenizer.pickle', 'rb') as handle:\n",
    "#    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W3vexp6c_CCv",
    "outputId": "df371f70-1e51-4ba4-f4e7-0a7cb7100a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 21\n"
     ]
    }
   ],
   "source": [
    "print(max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H87ixlDvzNz0",
    "outputId": "bd763137-dfcb-43a8-ca2f-ecb68b21739a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 1999 223 223\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size = 0.1 )\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2222, 21)\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwvATLwazTRZ"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eka\n"
     ]
    }
   ],
   "source": [
    "print(inp_lang.index_word[345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "qmOZS6-w9QFI",
    "outputId": "2a08dc60-3256-430e-eee5-99be15afbeb2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "509 ----> pensil\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "515 ----> pensil\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[100])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PPT0A8Q-9VJE",
    "outputId": "f7401332-b294-4597-85a9-85b25da0cf7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((2, 21), (2, 21)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 2\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 32\n",
    "units = 256\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YDk6DEoiDFsq",
    "outputId": "d948c61a-6e00-4153-8d5c-a8682c4b8c6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 21]), TensorShape([2, 21]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch, target_batch = next(iter(dataset))\n",
    "input_batch.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lDVlaVX_y4v"
   },
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "  if tf.test.is_gpu_available():\n",
    "    print('cuDNNGRU is Used')\n",
    "    return GRU(units, return_sequences=True, \n",
    "                           return_state=True, \n",
    "                           recurrent_initializer='glorot_uniform')\n",
    "  else:\n",
    "    print('GRU is used')\n",
    "    return GRU(units, return_sequences=True, \n",
    "                      return_state=True, \n",
    "                      recurrent_activation='sigmoid', \n",
    "                      recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teK1YcA2DtVR"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpnPUiV48cca"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights\n",
    "\n",
    "attention_layer = BahdanauAttention(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "mUrLM-bRf57y",
    "outputId": "be1cffe3-6e49-4d71-8e86-5124a30af71a"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        score = tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * max_length, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7dYaBu78pfU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class Decoder(tf.keras.Model):\\n  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\\n    super(Decoder, self).__init__()\\n    self.batch_sz = batch_sz\\n    self.dec_units = dec_units\\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\\n    self.gru = tf.keras.layers.GRU(self.dec_units,\\n                                   return_sequences=True,\\n                                   return_state=True,\\n                                   recurrent_initializer='glorot_uniform')\\n    self.fc = tf.keras.layers.Dense(vocab_size)\\n\\n    # used for attention\\n    self.attention = BahdanauAttention(self.dec_units)\\n\\n  def call(self, x, hidden, enc_output):\\n    # enc_output shape == (batch_size, max_length, hidden_size)\\n    context_vector, attention_weights = self.attention(hidden, enc_output)\\n\\n    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\\n    x = self.embedding(x)\\n\\n    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\\n    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\\n\\n    # passing the concatenated vector to the GRU\\n    output, state = self.gru(x)\\n\\n    # output shape == (batch_size * 1, hidden_size)\\n    output = tf.reshape(output, (-1, output.shape[2]))\\n\\n    # output shape == (batch_size, vocab)\\n    x = self.fc(output)\\n\\n    return x, state, attention_weights\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkHzbiweBBKn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\caesa\\AppData\\Local\\Temp\\ipykernel_16964\\481552359.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "cuDNNGRU is Used\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCv0X9CPBMta"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABtres4SNtUx"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpointss'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHatiEnCD4bO"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "t84vbnHTExZI",
    "outputId": "8f173d05-b9ca-4e5c-a136-e8ca09f14dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.6711\n",
      "Time taken for 1 batch 25.005852460861206 sec\n",
      "\n",
      "Epoch 1 Batch 100 Loss 0.5413\n",
      "Time taken for 1 batch 33.06681752204895 sec\n",
      "\n",
      "Epoch 1 Batch 200 Loss 0.5506\n",
      "Time taken for 1 batch 40.8688178062439 sec\n",
      "\n",
      "Epoch 1 Batch 300 Loss 0.7310\n",
      "Time taken for 1 batch 48.86310434341431 sec\n",
      "\n",
      "Epoch 1 Batch 400 Loss 1.0351\n",
      "Time taken for 1 batch 56.1061646938324 sec\n",
      "\n",
      "Epoch 1 Batch 500 Loss 0.3641\n",
      "Time taken for 1 batch 63.600616216659546 sec\n",
      "\n",
      "Epoch 1 Batch 600 Loss 0.3470\n",
      "Time taken for 1 batch 71.161616563797 sec\n",
      "\n",
      "Epoch 1 Batch 700 Loss 0.5354\n",
      "Time taken for 1 batch 78.89620780944824 sec\n",
      "\n",
      "Epoch 1 Batch 800 Loss 0.5538\n",
      "Time taken for 1 batch 86.58321785926819 sec\n",
      "\n",
      "Epoch 1 Batch 900 Loss 0.3806\n",
      "Time taken for 1 batch 94.96574187278748 sec\n",
      "\n",
      "Epoch 1 Loss 0.7190\n",
      "Time taken for 1 epoch 103.09934163093567 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.3315\n",
      "Time taken for 1 batch 0.09894132614135742 sec\n",
      "\n",
      "Epoch 2 Batch 100 Loss 0.5345\n",
      "Time taken for 1 batch 8.953951358795166 sec\n",
      "\n",
      "Epoch 2 Batch 200 Loss 0.6206\n",
      "Time taken for 1 batch 17.366942167282104 sec\n",
      "\n",
      "Epoch 2 Batch 300 Loss 0.4982\n",
      "Time taken for 1 batch 26.931060552597046 sec\n",
      "\n",
      "Epoch 2 Batch 400 Loss 0.4642\n",
      "Time taken for 1 batch 35.47494626045227 sec\n",
      "\n",
      "Epoch 2 Batch 500 Loss 0.3892\n",
      "Time taken for 1 batch 44.31794738769531 sec\n",
      "\n",
      "Epoch 2 Batch 600 Loss 0.4315\n",
      "Time taken for 1 batch 53.04094457626343 sec\n",
      "\n",
      "Epoch 2 Batch 700 Loss 0.9617\n",
      "Time taken for 1 batch 63.6510865688324 sec\n",
      "\n",
      "Epoch 2 Batch 800 Loss 0.5901\n",
      "Time taken for 1 batch 72.5710859298706 sec\n",
      "\n",
      "Epoch 2 Batch 900 Loss 0.6544\n",
      "Time taken for 1 batch 81.11413025856018 sec\n",
      "\n",
      "Epoch 2 Loss 0.6193\n",
      "Time taken for 1 epoch 89.31617856025696 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6223\n",
      "Time taken for 1 batch 0.07999920845031738 sec\n",
      "\n",
      "Epoch 3 Batch 100 Loss 0.2848\n",
      "Time taken for 1 batch 8.862952709197998 sec\n",
      "\n",
      "Epoch 3 Batch 200 Loss 0.4579\n",
      "Time taken for 1 batch 17.770952939987183 sec\n",
      "\n",
      "Epoch 3 Batch 300 Loss 0.4517\n",
      "Time taken for 1 batch 26.701956748962402 sec\n",
      "\n",
      "Epoch 3 Batch 400 Loss 0.6579\n",
      "Time taken for 1 batch 36.163650035858154 sec\n",
      "\n",
      "Epoch 3 Batch 500 Loss 0.2718\n",
      "Time taken for 1 batch 45.39620113372803 sec\n",
      "\n",
      "Epoch 3 Batch 600 Loss 0.3493\n",
      "Time taken for 1 batch 54.85419988632202 sec\n",
      "\n",
      "Epoch 3 Batch 700 Loss 0.5545\n",
      "Time taken for 1 batch 71.4759452342987 sec\n",
      "\n",
      "Epoch 3 Batch 800 Loss 0.6516\n",
      "Time taken for 1 batch 85.26505184173584 sec\n",
      "\n",
      "Epoch 3 Batch 900 Loss 0.6082\n",
      "Time taken for 1 batch 98.97010660171509 sec\n",
      "\n",
      "Epoch 3 Loss 0.5567\n",
      "Time taken for 1 epoch 111.59943175315857 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.4199\n",
      "Time taken for 1 batch 0.08098649978637695 sec\n",
      "\n",
      "Epoch 4 Batch 100 Loss 0.3764\n",
      "Time taken for 1 batch 11.671459913253784 sec\n",
      "\n",
      "Epoch 4 Batch 200 Loss 0.3095\n",
      "Time taken for 1 batch 22.957693815231323 sec\n",
      "\n",
      "Epoch 4 Batch 300 Loss 0.4379\n",
      "Time taken for 1 batch 37.34674406051636 sec\n",
      "\n",
      "Epoch 4 Batch 400 Loss 0.5977\n",
      "Time taken for 1 batch 55.385517835617065 sec\n",
      "\n",
      "Epoch 4 Batch 500 Loss 0.9939\n",
      "Time taken for 1 batch 73.38875150680542 sec\n",
      "\n",
      "Epoch 4 Batch 600 Loss 0.2719\n",
      "Time taken for 1 batch 91.33754587173462 sec\n",
      "\n",
      "Epoch 4 Batch 700 Loss 0.6258\n",
      "Time taken for 1 batch 107.64358854293823 sec\n",
      "\n",
      "Epoch 4 Batch 800 Loss 0.6814\n",
      "Time taken for 1 batch 123.07810401916504 sec\n",
      "\n",
      "Epoch 4 Batch 900 Loss 0.3106\n",
      "Time taken for 1 batch 137.4806981086731 sec\n",
      "\n",
      "Epoch 4 Loss 0.5042\n",
      "Time taken for 1 epoch 152.35252976417542 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2298\n",
      "Time taken for 1 batch 0.18901824951171875 sec\n",
      "\n",
      "Epoch 5 Batch 100 Loss 0.2992\n",
      "Time taken for 1 batch 14.031001806259155 sec\n",
      "\n",
      "Epoch 5 Batch 200 Loss 0.2630\n",
      "Time taken for 1 batch 28.02254891395569 sec\n",
      "\n",
      "Epoch 5 Batch 300 Loss 0.3521\n",
      "Time taken for 1 batch 41.74446940422058 sec\n",
      "\n",
      "Epoch 5 Batch 400 Loss 0.6552\n",
      "Time taken for 1 batch 55.441996812820435 sec\n",
      "\n",
      "Epoch 5 Batch 500 Loss 0.3993\n",
      "Time taken for 1 batch 70.31281447410583 sec\n",
      "\n",
      "Epoch 5 Batch 600 Loss 0.2374\n",
      "Time taken for 1 batch 84.43681001663208 sec\n",
      "\n",
      "Epoch 5 Batch 700 Loss 0.2459\n",
      "Time taken for 1 batch 96.75481247901917 sec\n",
      "\n",
      "Epoch 5 Batch 800 Loss 0.2946\n",
      "Time taken for 1 batch 109.52444195747375 sec\n",
      "\n",
      "Epoch 5 Batch 900 Loss 0.4714\n",
      "Time taken for 1 batch 122.83422422409058 sec\n",
      "\n",
      "Epoch 5 Loss 0.4558\n",
      "Time taken for 1 epoch 135.4645779132843 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1985\n",
      "Time taken for 1 batch 0.07856035232543945 sec\n",
      "\n",
      "Epoch 6 Batch 100 Loss 0.3299\n",
      "Time taken for 1 batch 11.245988607406616 sec\n",
      "\n",
      "Epoch 6 Batch 200 Loss 0.7171\n",
      "Time taken for 1 batch 22.494367122650146 sec\n",
      "\n",
      "Epoch 6 Batch 300 Loss 0.2292\n",
      "Time taken for 1 batch 33.55328941345215 sec\n",
      "\n",
      "Epoch 6 Batch 400 Loss 0.3166\n",
      "Time taken for 1 batch 44.12720990180969 sec\n",
      "\n",
      "Epoch 6 Batch 500 Loss 0.3652\n",
      "Time taken for 1 batch 54.457566261291504 sec\n",
      "\n",
      "Epoch 6 Batch 600 Loss 0.4663\n",
      "Time taken for 1 batch 64.83469223976135 sec\n",
      "\n",
      "Epoch 6 Batch 700 Loss 0.9418\n",
      "Time taken for 1 batch 75.22672152519226 sec\n",
      "\n",
      "Epoch 6 Batch 800 Loss 0.3754\n",
      "Time taken for 1 batch 85.70963740348816 sec\n",
      "\n",
      "Epoch 6 Batch 900 Loss 0.6640\n",
      "Time taken for 1 batch 95.94694662094116 sec\n",
      "\n",
      "Epoch 6 Loss 0.4184\n",
      "Time taken for 1 epoch 106.14832901954651 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.5799\n",
      "Time taken for 1 batch 0.1411454677581787 sec\n",
      "\n",
      "Epoch 7 Batch 100 Loss 0.3531\n",
      "Time taken for 1 batch 10.403385400772095 sec\n",
      "\n",
      "Epoch 7 Batch 200 Loss 0.2706\n",
      "Time taken for 1 batch 20.6332528591156 sec\n",
      "\n",
      "Epoch 7 Batch 300 Loss 0.5314\n",
      "Time taken for 1 batch 30.944039344787598 sec\n",
      "\n",
      "Epoch 7 Batch 400 Loss 0.4819\n",
      "Time taken for 1 batch 41.14293360710144 sec\n",
      "\n",
      "Epoch 7 Batch 500 Loss 0.2012\n",
      "Time taken for 1 batch 51.81469106674194 sec\n",
      "\n",
      "Epoch 7 Batch 600 Loss 0.7720\n",
      "Time taken for 1 batch 61.82034730911255 sec\n",
      "\n",
      "Epoch 7 Batch 700 Loss 0.2363\n",
      "Time taken for 1 batch 71.67846345901489 sec\n",
      "\n",
      "Epoch 7 Batch 800 Loss 0.5709\n",
      "Time taken for 1 batch 81.54620099067688 sec\n",
      "\n",
      "Epoch 7 Batch 900 Loss 0.4192\n",
      "Time taken for 1 batch 91.52022552490234 sec\n",
      "\n",
      "Epoch 7 Loss 0.3808\n",
      "Time taken for 1 epoch 101.40050983428955 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2059\n",
      "Time taken for 1 batch 0.11839127540588379 sec\n",
      "\n",
      "Epoch 8 Batch 100 Loss 0.3702\n",
      "Time taken for 1 batch 9.966036558151245 sec\n",
      "\n",
      "Epoch 8 Batch 200 Loss 0.3277\n",
      "Time taken for 1 batch 20.499072313308716 sec\n",
      "\n",
      "Epoch 8 Batch 300 Loss 0.4398\n",
      "Time taken for 1 batch 30.436832904815674 sec\n",
      "\n",
      "Epoch 8 Batch 400 Loss 0.3657\n",
      "Time taken for 1 batch 39.95505714416504 sec\n",
      "\n",
      "Epoch 8 Batch 500 Loss 0.6901\n",
      "Time taken for 1 batch 49.92894697189331 sec\n",
      "\n",
      "Epoch 8 Batch 600 Loss 0.3830\n",
      "Time taken for 1 batch 60.04314398765564 sec\n",
      "\n",
      "Epoch 8 Batch 700 Loss 0.3016\n",
      "Time taken for 1 batch 69.3830087184906 sec\n",
      "\n",
      "Epoch 8 Batch 800 Loss 0.2430\n",
      "Time taken for 1 batch 79.17121458053589 sec\n",
      "\n",
      "Epoch 8 Batch 900 Loss 0.3038\n",
      "Time taken for 1 batch 88.91112542152405 sec\n",
      "\n",
      "Epoch 8 Loss 0.3458\n",
      "Time taken for 1 epoch 98.21097040176392 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.2371\n",
      "Time taken for 1 batch 0.07853055000305176 sec\n",
      "\n",
      "Epoch 9 Batch 100 Loss 0.1232\n",
      "Time taken for 1 batch 9.691380977630615 sec\n",
      "\n",
      "Epoch 9 Batch 200 Loss 0.3866\n",
      "Time taken for 1 batch 19.010902643203735 sec\n",
      "\n",
      "Epoch 9 Batch 300 Loss 0.3216\n",
      "Time taken for 1 batch 28.616349935531616 sec\n",
      "\n",
      "Epoch 9 Batch 400 Loss 0.2629\n",
      "Time taken for 1 batch 38.214722633361816 sec\n",
      "\n",
      "Epoch 9 Batch 500 Loss 0.3502\n",
      "Time taken for 1 batch 47.52462911605835 sec\n",
      "\n",
      "Epoch 9 Batch 600 Loss 0.2095\n",
      "Time taken for 1 batch 57.0259473323822 sec\n",
      "\n",
      "Epoch 9 Batch 700 Loss 0.2347\n",
      "Time taken for 1 batch 66.36404752731323 sec\n",
      "\n",
      "Epoch 9 Batch 800 Loss 0.2462\n",
      "Time taken for 1 batch 75.66154670715332 sec\n",
      "\n",
      "Epoch 9 Batch 900 Loss 0.2354\n",
      "Time taken for 1 batch 84.77909755706787 sec\n",
      "\n",
      "Epoch 9 Loss 0.3126\n",
      "Time taken for 1 epoch 94.47292852401733 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2120\n",
      "Time taken for 1 batch 0.1559147834777832 sec\n",
      "\n",
      "Epoch 10 Batch 100 Loss 0.4935\n",
      "Time taken for 1 batch 9.382120370864868 sec\n",
      "\n",
      "Epoch 10 Batch 200 Loss 0.2286\n",
      "Time taken for 1 batch 18.641247272491455 sec\n",
      "\n",
      "Epoch 10 Batch 300 Loss 0.3131\n",
      "Time taken for 1 batch 28.166483640670776 sec\n",
      "\n",
      "Epoch 10 Batch 400 Loss 0.2626\n",
      "Time taken for 1 batch 37.42203426361084 sec\n",
      "\n",
      "Epoch 10 Batch 500 Loss 0.5286\n",
      "Time taken for 1 batch 46.75200533866882 sec\n",
      "\n",
      "Epoch 10 Batch 600 Loss 0.3843\n",
      "Time taken for 1 batch 56.1045138835907 sec\n",
      "\n",
      "Epoch 10 Batch 700 Loss 0.3436\n",
      "Time taken for 1 batch 65.50357580184937 sec\n",
      "\n",
      "Epoch 10 Batch 800 Loss 0.1472\n",
      "Time taken for 1 batch 74.86865282058716 sec\n",
      "\n",
      "Epoch 10 Batch 900 Loss 0.2239\n",
      "Time taken for 1 batch 84.12869596481323 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 0.2803\n",
      "Time taken for 1 epoch 93.29339575767517 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss = total_loss + batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "      print('Time taken for 1 batch {} sec\\n'.format(time.time() - start))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    " # if (epoch + 1) % 2 == 0:\n",
    " #   checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hIbkNJWl750m"
   },
   "outputs": [],
   "source": [
    "#checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "#checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuFVut942Ko8"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpointss\\\\ckpt-1'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxNPS1aTNI-r"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "import matplotlib.ticker as ticker\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-w3W6IfWxYD7"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "x00g29wuxicN",
    "outputId": "da066001-9d4e-4d45-f092-70f72311c3be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#translate(u'narai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "xKZXcyVMxvTA",
    "outputId": "40f2926a-0580-46eb-b79e-6bf6eae8a52d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> aku lagih mandai <end>\n",
      "Predicted translation: aku sayang padamu <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caesa\\AppData\\Local\\Temp\\ipykernel_16964\\2979653732.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "C:\\Users\\caesa\\AppData\\Local\\Temp\\ipykernel_16964\\2979653732.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'narai kabar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate(u'que fais tu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt (5).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
