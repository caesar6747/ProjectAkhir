{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "b6ZIUpwFih7a",
    "outputId": "3f00b5c8-d94c-4f2b-c0a4-0d80a4b9224a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\ndrive.mount('/gdrive')\\n%cd /gdrive\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQ7C1ecfiqcI"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from numpy import array, argmax, random, take\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNGRU\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import unicodedata\n",
    "import io\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o88uz_9kmSxS"
   },
   "outputs": [],
   "source": [
    "#path_to_file = '/content/fra1.txt'\n",
    "#path_to_file = '/content/drive/My Drive/Colab Notebooks/fra1.txt'\n",
    "path_to_file = 'dayak.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OB9IkJCm75L"
   },
   "outputs": [],
   "source": [
    "def unicode_to_acii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itS-QoVznJ64"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_acii(w.lower().strip())\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "  w = w.strip()\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RXJryIzrr_-s",
    "outputId": "ce3f3d99-96a0-4c55-a365-eaf9b1a47a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> puis je emprunter ce livre ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "fr_sentence = u\"Puis-je emprunter ce livre?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(fr_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWrJ3arQtBpY"
   },
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "uSPFRdBIt9eM",
    "outputId": "6b9c77bc-1a71-4aaa-b51c-2782379e7488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> apa kabar <end>\n",
      "<start> narai kabar <end>\n",
      "====\n",
      "<start> apa katanya <end>\n",
      "<start> narai kua <end>\n",
      "====\n",
      "<start> aku pulang <end>\n",
      "<start> aku buli <end>\n",
      "====\n",
      "<start> aku sedang belajar <end>\n",
      "<start> aku lagih belajar <end>\n",
      "====\n",
      "<start> aku mau makan <end>\n",
      "<start> aku handak kuman <end>\n",
      "====\n",
      "<start> aku datang <end>\n",
      "<start> aku dumah <end>\n",
      "====\n",
      "<start> aku pergi <end>\n",
      "<start> aku tulak <end>\n",
      "====\n",
      "<start> aku sudah menjawab pertanyaan <end>\n",
      "<start> aku jadi manjawab pertanyaan <end>\n",
      "====\n",
      "<start> aku suka kamu <end>\n",
      "<start> aku handak dengam <end>\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "en, fr = create_dataset(path_to_file, None)\n",
    "for s in range(9):\n",
    "    print(en[s])\n",
    "    print(fr[s])\n",
    "    print('====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGZ6n267uGC4"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQ8FB5U9y1jU"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "  \n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sWcBu21y3mn"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 2222\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x00000140727D7BE0>\n"
     ]
    }
   ],
   "source": [
    "print(inp_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('inp_lang.pickle', 'wb') as handle:\n",
    "    pickle.dump(inp_lang, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('targ_lang.pickle', 'wb') as handle:\n",
    "    pickle.dump(targ_lang, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "#with open('tokenizer.pickle', 'rb') as handle:\n",
    "#    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W3vexp6c_CCv",
    "outputId": "df371f70-1e51-4ba4-f4e7-0a7cb7100a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 21\n"
     ]
    }
   ],
   "source": [
    "print(max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H87ixlDvzNz0",
    "outputId": "bd763137-dfcb-43a8-ca2f-ecb68b21739a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 1999 223 223\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size = 0.1 )\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2222, 21)\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwvATLwazTRZ"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eka\n"
     ]
    }
   ],
   "source": [
    "print(inp_lang.index_word[345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "qmOZS6-w9QFI",
    "outputId": "2a08dc60-3256-430e-eee5-99be15afbeb2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "421 ----> belok\n",
      "313 ----> sambil\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "443 ----> belok\n",
      "328 ----> kiri\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[100])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PPT0A8Q-9VJE",
    "outputId": "f7401332-b294-4597-85a9-85b25da0cf7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((2, 21), (2, 21)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 2\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 32\n",
    "units = 256\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YDk6DEoiDFsq",
    "outputId": "d948c61a-6e00-4153-8d5c-a8682c4b8c6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 21]), TensorShape([2, 21]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch, target_batch = next(iter(dataset))\n",
    "input_batch.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lDVlaVX_y4v"
   },
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "  if tf.test.is_gpu_available():\n",
    "    print('cuDNNGRU is Used')\n",
    "    return GRU(units, return_sequences=True, \n",
    "                           return_state=True, \n",
    "                           recurrent_initializer='glorot_uniform')\n",
    "  else:\n",
    "    print('GRU is used')\n",
    "    return GRU(units, return_sequences=True, \n",
    "                      return_state=True, \n",
    "                      recurrent_activation='sigmoid', \n",
    "                      recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "teK1YcA2DtVR"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpnPUiV48cca"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights\n",
    "\n",
    "attention_layer = BahdanauAttention(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "mUrLM-bRf57y",
    "outputId": "be1cffe3-6e49-4d71-8e86-5124a30af71a"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        score = tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * max_length, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7dYaBu78pfU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class Decoder(tf.keras.Model):\\n  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\\n    super(Decoder, self).__init__()\\n    self.batch_sz = batch_sz\\n    self.dec_units = dec_units\\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\\n    self.gru = tf.keras.layers.GRU(self.dec_units,\\n                                   return_sequences=True,\\n                                   return_state=True,\\n                                   recurrent_initializer='glorot_uniform')\\n    self.fc = tf.keras.layers.Dense(vocab_size)\\n\\n    # used for attention\\n    self.attention = BahdanauAttention(self.dec_units)\\n\\n  def call(self, x, hidden, enc_output):\\n    # enc_output shape == (batch_size, max_length, hidden_size)\\n    context_vector, attention_weights = self.attention(hidden, enc_output)\\n\\n    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\\n    x = self.embedding(x)\\n\\n    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\\n    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\\n\\n    # passing the concatenated vector to the GRU\\n    output, state = self.gru(x)\\n\\n    # output shape == (batch_size * 1, hidden_size)\\n    output = tf.reshape(output, (-1, output.shape[2]))\\n\\n    # output shape == (batch_size, vocab)\\n    x = self.fc(output)\\n\\n    return x, state, attention_weights\\n\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkHzbiweBBKn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuDNNGRU is Used\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCv0X9CPBMta"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABtres4SNtUx"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpointss'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHatiEnCD4bO"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "t84vbnHTExZI",
    "outputId": "8f173d05-b9ca-4e5c-a136-e8ca09f14dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.0065\n",
      "Time taken for 1 batch 18.776151418685913 sec\n",
      "\n",
      "Epoch 1 Batch 100 Loss 0.6224\n",
      "Time taken for 1 batch 24.420894861221313 sec\n",
      "\n",
      "Epoch 1 Batch 200 Loss 1.1827\n",
      "Time taken for 1 batch 30.112480878829956 sec\n",
      "\n",
      "Epoch 1 Batch 300 Loss 1.0013\n",
      "Time taken for 1 batch 36.05633568763733 sec\n",
      "\n",
      "Epoch 1 Batch 400 Loss 0.5582\n",
      "Time taken for 1 batch 41.90521287918091 sec\n",
      "\n",
      "Epoch 1 Batch 500 Loss 1.0926\n",
      "Time taken for 1 batch 47.737738847732544 sec\n",
      "\n",
      "Epoch 1 Batch 600 Loss 0.8705\n",
      "Time taken for 1 batch 53.492592573165894 sec\n",
      "\n",
      "Epoch 1 Batch 700 Loss 0.5576\n",
      "Time taken for 1 batch 58.99691295623779 sec\n",
      "\n",
      "Epoch 1 Batch 800 Loss 0.7889\n",
      "Time taken for 1 batch 64.51522397994995 sec\n",
      "\n",
      "Epoch 1 Batch 900 Loss 0.7590\n",
      "Time taken for 1 batch 70.17608308792114 sec\n",
      "\n",
      "Epoch 1 Loss 0.7269\n",
      "Time taken for 1 epoch 75.71265172958374 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.1345\n",
      "Time taken for 1 batch 0.06300139427185059 sec\n",
      "\n",
      "Epoch 2 Batch 100 Loss 0.4879\n",
      "Time taken for 1 batch 5.692646503448486 sec\n",
      "\n",
      "Epoch 2 Batch 200 Loss 0.6772\n",
      "Time taken for 1 batch 11.430711030960083 sec\n",
      "\n",
      "Epoch 2 Batch 300 Loss 0.7951\n",
      "Time taken for 1 batch 17.029040813446045 sec\n",
      "\n",
      "Epoch 2 Batch 400 Loss 0.4963\n",
      "Time taken for 1 batch 22.721055030822754 sec\n",
      "\n",
      "Epoch 2 Batch 500 Loss 0.6240\n",
      "Time taken for 1 batch 28.366453647613525 sec\n",
      "\n",
      "Epoch 2 Batch 600 Loss 0.6301\n",
      "Time taken for 1 batch 33.995763063430786 sec\n",
      "\n",
      "Epoch 2 Batch 700 Loss 0.3305\n",
      "Time taken for 1 batch 39.60869264602661 sec\n",
      "\n",
      "Epoch 2 Batch 800 Loss 0.8574\n",
      "Time taken for 1 batch 45.301000118255615 sec\n",
      "\n",
      "Epoch 2 Batch 900 Loss 0.5938\n",
      "Time taken for 1 batch 52.31652641296387 sec\n",
      "\n",
      "Epoch 2 Loss 0.6337\n",
      "Time taken for 1 epoch 58.42543005943298 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.3076\n",
      "Time taken for 1 batch 0.04687356948852539 sec\n",
      "\n",
      "Epoch 3 Batch 100 Loss 0.7614\n",
      "Time taken for 1 batch 6.102996587753296 sec\n",
      "\n",
      "Epoch 3 Batch 200 Loss 0.5872\n",
      "Time taken for 1 batch 12.310156106948853 sec\n",
      "\n",
      "Epoch 3 Batch 300 Loss 0.7804\n",
      "Time taken for 1 batch 18.110750198364258 sec\n",
      "\n",
      "Epoch 3 Batch 400 Loss 0.4730\n",
      "Time taken for 1 batch 23.8503201007843 sec\n",
      "\n",
      "Epoch 3 Batch 500 Loss 0.5883\n",
      "Time taken for 1 batch 29.683678150177002 sec\n",
      "\n",
      "Epoch 3 Batch 600 Loss 0.3454\n",
      "Time taken for 1 batch 35.53481912612915 sec\n",
      "\n",
      "Epoch 3 Batch 700 Loss 0.3372\n",
      "Time taken for 1 batch 41.246317863464355 sec\n",
      "\n",
      "Epoch 3 Batch 800 Loss 0.4922\n",
      "Time taken for 1 batch 47.1987669467926 sec\n",
      "\n",
      "Epoch 3 Batch 900 Loss 0.5436\n",
      "Time taken for 1 batch 52.906498193740845 sec\n",
      "\n",
      "Epoch 3 Loss 0.5700\n",
      "Time taken for 1 epoch 58.59807825088501 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.4914\n",
      "Time taken for 1 batch 0.06250214576721191 sec\n",
      "\n",
      "Epoch 4 Batch 100 Loss 0.5025\n",
      "Time taken for 1 batch 5.833826780319214 sec\n",
      "\n",
      "Epoch 4 Batch 200 Loss 0.7581\n",
      "Time taken for 1 batch 11.703161478042603 sec\n",
      "\n",
      "Epoch 4 Batch 300 Loss 0.4268\n",
      "Time taken for 1 batch 17.337420225143433 sec\n",
      "\n",
      "Epoch 4 Batch 400 Loss 0.4594\n",
      "Time taken for 1 batch 25.52935004234314 sec\n",
      "\n",
      "Epoch 4 Batch 500 Loss 0.5826\n",
      "Time taken for 1 batch 39.05877470970154 sec\n",
      "\n",
      "Epoch 4 Batch 600 Loss 0.4968\n",
      "Time taken for 1 batch 47.89026379585266 sec\n",
      "\n",
      "Epoch 4 Batch 700 Loss 0.5934\n",
      "Time taken for 1 batch 59.5413281917572 sec\n",
      "\n",
      "Epoch 4 Batch 800 Loss 0.4144\n",
      "Time taken for 1 batch 71.14387774467468 sec\n",
      "\n",
      "Epoch 4 Batch 900 Loss 0.4739\n",
      "Time taken for 1 batch 84.95275044441223 sec\n",
      "\n",
      "Epoch 4 Loss 0.5163\n",
      "Time taken for 1 epoch 101.62605857849121 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2294\n",
      "Time taken for 1 batch 0.17319750785827637 sec\n",
      "\n",
      "Epoch 5 Batch 100 Loss 0.6446\n",
      "Time taken for 1 batch 16.54359531402588 sec\n",
      "\n",
      "Epoch 5 Batch 200 Loss 0.5043\n",
      "Time taken for 1 batch 34.31015157699585 sec\n",
      "\n",
      "Epoch 5 Batch 300 Loss 0.4310\n",
      "Time taken for 1 batch 53.330602407455444 sec\n",
      "\n",
      "Epoch 5 Batch 400 Loss 0.6264\n",
      "Time taken for 1 batch 72.41597509384155 sec\n",
      "\n",
      "Epoch 5 Batch 500 Loss 0.8772\n",
      "Time taken for 1 batch 91.44995212554932 sec\n",
      "\n",
      "Epoch 5 Batch 600 Loss 0.3324\n",
      "Time taken for 1 batch 110.5330171585083 sec\n",
      "\n",
      "Epoch 5 Batch 700 Loss 0.2738\n",
      "Time taken for 1 batch 129.61686325073242 sec\n",
      "\n",
      "Epoch 5 Batch 800 Loss 0.6736\n",
      "Time taken for 1 batch 148.70041632652283 sec\n",
      "\n",
      "Epoch 5 Batch 900 Loss 0.4491\n",
      "Time taken for 1 batch 167.90899753570557 sec\n",
      "\n",
      "Epoch 5 Loss 0.4673\n",
      "Time taken for 1 epoch 186.63446187973022 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4971\n",
      "Time taken for 1 batch 0.1850578784942627 sec\n",
      "\n",
      "Epoch 6 Batch 100 Loss 0.7691\n",
      "Time taken for 1 batch 19.294940948486328 sec\n",
      "\n",
      "Epoch 6 Batch 200 Loss 0.2020\n",
      "Time taken for 1 batch 38.35250186920166 sec\n",
      "\n",
      "Epoch 6 Batch 300 Loss 0.2642\n",
      "Time taken for 1 batch 57.435234785079956 sec\n",
      "\n",
      "Epoch 6 Batch 400 Loss 0.3147\n",
      "Time taken for 1 batch 76.48876929283142 sec\n",
      "\n",
      "Epoch 6 Batch 500 Loss 0.5300\n",
      "Time taken for 1 batch 95.58662128448486 sec\n",
      "\n",
      "Epoch 6 Batch 600 Loss 0.3762\n",
      "Time taken for 1 batch 114.59166860580444 sec\n",
      "\n",
      "Epoch 6 Batch 700 Loss 0.2831\n",
      "Time taken for 1 batch 133.4252951145172 sec\n",
      "\n",
      "Epoch 6 Batch 800 Loss 0.4646\n",
      "Time taken for 1 batch 149.1352822780609 sec\n",
      "\n",
      "Epoch 6 Batch 900 Loss 0.3962\n",
      "Time taken for 1 batch 166.5886309146881 sec\n",
      "\n",
      "Epoch 6 Loss 0.4185\n",
      "Time taken for 1 epoch 181.92517185211182 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.3113\n",
      "Time taken for 1 batch 0.15665102005004883 sec\n",
      "\n",
      "Epoch 7 Batch 100 Loss 0.6698\n",
      "Time taken for 1 batch 16.41778326034546 sec\n",
      "\n",
      "Epoch 7 Batch 200 Loss 0.2733\n",
      "Time taken for 1 batch 34.168163537979126 sec\n",
      "\n",
      "Epoch 7 Batch 300 Loss 0.3588\n",
      "Time taken for 1 batch 51.494231939315796 sec\n",
      "\n",
      "Epoch 7 Batch 400 Loss 0.2131\n",
      "Time taken for 1 batch 67.51978874206543 sec\n",
      "\n",
      "Epoch 7 Batch 500 Loss 0.1820\n",
      "Time taken for 1 batch 84.5186870098114 sec\n",
      "\n",
      "Epoch 7 Batch 600 Loss 0.2719\n",
      "Time taken for 1 batch 100.76322889328003 sec\n",
      "\n",
      "Epoch 7 Batch 700 Loss 0.2724\n",
      "Time taken for 1 batch 117.00136423110962 sec\n",
      "\n",
      "Epoch 7 Batch 800 Loss 0.2277\n",
      "Time taken for 1 batch 133.88048386573792 sec\n",
      "\n",
      "Epoch 7 Batch 900 Loss 0.4153\n",
      "Time taken for 1 batch 149.38870525360107 sec\n",
      "\n",
      "Epoch 7 Loss 0.3755\n",
      "Time taken for 1 epoch 165.30466508865356 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.3669\n",
      "Time taken for 1 batch 0.17228078842163086 sec\n",
      "\n",
      "Epoch 8 Batch 100 Loss 0.2556\n",
      "Time taken for 1 batch 16.098080158233643 sec\n",
      "\n",
      "Epoch 8 Batch 200 Loss 0.2372\n",
      "Time taken for 1 batch 32.31771230697632 sec\n",
      "\n",
      "Epoch 8 Batch 300 Loss 0.2170\n",
      "Time taken for 1 batch 48.51637649536133 sec\n",
      "\n",
      "Epoch 8 Batch 400 Loss 0.2203\n",
      "Time taken for 1 batch 63.208508014678955 sec\n",
      "\n",
      "Epoch 8 Batch 500 Loss 0.2091\n",
      "Time taken for 1 batch 79.4698874950409 sec\n",
      "\n",
      "Epoch 8 Batch 600 Loss 0.3387\n",
      "Time taken for 1 batch 95.6832332611084 sec\n",
      "\n",
      "Epoch 8 Batch 700 Loss 0.2720\n",
      "Time taken for 1 batch 110.65854668617249 sec\n",
      "\n",
      "Epoch 8 Batch 800 Loss 0.3655\n",
      "Time taken for 1 batch 126.8566472530365 sec\n",
      "\n",
      "Epoch 8 Batch 900 Loss 0.6926\n",
      "Time taken for 1 batch 139.43211388587952 sec\n",
      "\n",
      "Epoch 8 Loss 0.3305\n",
      "Time taken for 1 epoch 152.18109154701233 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.2359\n",
      "Time taken for 1 batch 0.06290721893310547 sec\n",
      "\n",
      "Epoch 9 Batch 100 Loss 0.1344\n",
      "Time taken for 1 batch 10.192558288574219 sec\n",
      "\n",
      "Epoch 9 Batch 200 Loss 0.3820\n",
      "Time taken for 1 batch 22.03076481819153 sec\n",
      "\n",
      "Epoch 9 Batch 300 Loss 0.2481\n",
      "Time taken for 1 batch 34.95159435272217 sec\n",
      "\n",
      "Epoch 9 Batch 400 Loss 0.3452\n",
      "Time taken for 1 batch 47.325185775756836 sec\n",
      "\n",
      "Epoch 9 Batch 500 Loss 0.3424\n",
      "Time taken for 1 batch 59.47638440132141 sec\n",
      "\n",
      "Epoch 9 Batch 600 Loss 0.2003\n",
      "Time taken for 1 batch 68.64244961738586 sec\n",
      "\n",
      "Epoch 9 Batch 700 Loss 0.2525\n",
      "Time taken for 1 batch 77.69695591926575 sec\n",
      "\n",
      "Epoch 9 Batch 800 Loss 0.2200\n",
      "Time taken for 1 batch 87.3424825668335 sec\n",
      "\n",
      "Epoch 9 Batch 900 Loss 0.6997\n",
      "Time taken for 1 batch 96.65556573867798 sec\n",
      "\n",
      "Epoch 9 Loss 0.2910\n",
      "Time taken for 1 epoch 105.67366051673889 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1307\n",
      "Time taken for 1 batch 0.062000274658203125 sec\n",
      "\n",
      "Epoch 10 Batch 100 Loss 0.1780\n",
      "Time taken for 1 batch 8.716461181640625 sec\n",
      "\n",
      "Epoch 10 Batch 200 Loss 0.2581\n",
      "Time taken for 1 batch 18.196303606033325 sec\n",
      "\n",
      "Epoch 10 Batch 300 Loss 0.3451\n",
      "Time taken for 1 batch 26.2949960231781 sec\n",
      "\n",
      "Epoch 10 Batch 400 Loss 0.0678\n",
      "Time taken for 1 batch 36.20747685432434 sec\n",
      "\n",
      "Epoch 10 Batch 500 Loss 0.2269\n",
      "Time taken for 1 batch 44.50027561187744 sec\n",
      "\n",
      "Epoch 10 Batch 600 Loss 0.2928\n",
      "Time taken for 1 batch 53.46238660812378 sec\n",
      "\n",
      "Epoch 10 Batch 700 Loss 0.7007\n",
      "Time taken for 1 batch 62.18468523025513 sec\n",
      "\n",
      "Epoch 10 Batch 800 Loss 0.1907\n",
      "Time taken for 1 batch 70.37298560142517 sec\n",
      "\n",
      "Epoch 10 Batch 900 Loss 0.1646\n",
      "Time taken for 1 batch 77.71140956878662 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 0.2484\n",
      "Time taken for 1 epoch 85.78620052337646 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss = total_loss + batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "      print('Time taken for 1 batch {} sec\\n'.format(time.time() - start))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    " # if (epoch + 1) % 2 == 0:\n",
    " #   checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hIbkNJWl750m"
   },
   "outputs": [],
   "source": [
    "#checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "#checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuFVut942Ko8"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpointss\\\\ckpt-1'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxNPS1aTNI-r"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "import matplotlib.ticker as ticker\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-w3W6IfWxYD7"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "x00g29wuxicN",
    "outputId": "da066001-9d4e-4d45-f092-70f72311c3be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#translate(u'narai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "xKZXcyVMxvTA",
    "outputId": "40f2926a-0580-46eb-b79e-6bf6eae8a52d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> aku lagih mandai <end>\n",
      "Predicted translation: aku sedang berusaha <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caesa\\AppData\\Local\\Temp\\ipykernel_25448\\2979653732.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "C:\\Users\\caesa\\AppData\\Local\\Temp\\ipykernel_25448\\2979653732.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'aku lagih mandai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate(u'que fais tu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt (5).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
